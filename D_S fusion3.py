from osgeo import gdal
import csv
import numpy as np
import pandas as pd
from tqdm import tqdm
from tqdm import tqdm

def fusion(a, b, c, d):
    m1 = np.array(a)
    m2 = np.array(b)
    m3 = np.array(c)
    k = 0
    for i in range(len(a)):
        for j in range(len(a)):
            for ij in range(len(a)):
                k = k + m1[i] * m2[j] * m3[ij]
    res = 0
    for q in range(len(a)):
        res = res + m1[q] * m2[q] * m3[q]
    k = k - res

    list = []
    for s in range(len(a)):
        A = m1[s] * m2[s] * m3[s] / (1 - k)
        list.append(A)

    list2 = []
    for t in range(len(a)):
        P = list[t] / np.sum(list)
        list2.append(P)

    if not list2:
        # 处理list2为空的情况，例如返回一个特定值
        return [d, 225]

    result = [d, list2.index(max(list2)) + 1]
    return result

clcd_dict = {
    1:np.array([0.82919146,	0.073369565,	0,	0.044289044,	0.035433071	,0,	0,	0.203125,	0]),
    2:np.array([0.043752188,	0.807744565,	0.457142857,	0.013986014	,0.003937008	,0.002949853,	0,	0.017857143,	0]),
    3:np.array([0.029751488,	0.068274457	,0.4,	0.063714064	,0	,0,	0.012940331,	0.013392857,	0]),
    4: np.array([0.031501575	,0.036005435	,0.142857143,	0.565656566,	0.003937008,	0.002949853,	0.069015097,	0.013392857	,0]),
    5:np.array([0.009100455,	0.005434783,	0	,0.004273504	,0.846456693,	0	,0.003594536,	0.033482143,	0]),
    6:np.array([0,	0.002377717,	0,	0.031080031	,0.039370079,	0.970501475	,0.03666427,	0	,0]),
    7:np.array([0.002450123	,0.000339674	,0,	0.252913753,	0.007874016,	0.020648968,	0.868439971,	0.008928571,	0]),
    8:np.array([0.039901995,0.004076087,	0,	0.007381507,	0,	0	,0	,0.678571429,	0]),
    9:np.array([0.014350718	,0.002377717,	0	,0.016705517,	0.062992126,	0.002949853,	0.009345794,	0.03125	,1])}

lucc_dict = {
1:np.array([0.777691108,	0.122645642	,0.106227106	,0.087490407,	0.147058824,	0	,0.01018574	,0.282377919,	0.25]),
2:np.array([0.087363495,	0.757336837,	0.582417582,	0.103223331,	0.022058824,	0,	0.001198322	,0.023354565	,0.030612245]),
3:np.array([0.028081123	,0.052124398	,0.131868132,	0.059094398	,0.025735294	,0,	0.028160575	,0.014861996,	0.051020408]),
4:np.array([0.028081123,	0.041173894,	0.152014652,	0.464313124,	0.029411765,	0.008438819,	0.139604554,	0.016985138	,0.260204082]),
5:np.array([0.014430577,	0.009198423	,0.001831502,	0.004221028,	0.676470588,	0	,0.002995806,	0.025477707	,0.086734694]),
6:np.array([0,	0.005694262,	0.001831502,	0.039524175,	0.007352941	,0.974683544,	0.076093469	,0,	0]),
7:np.array([0.014430577,	0.003066141,	0.005494505,	0.224481965,	0.003676471,	0.016877637,	0.731575794,	0.008492569	,0.091836735]),
8:np.array([0.044461778,	0.007446343,	0.014652015	,0.003453569,	0.022058824,	0,	0.000599161,	0.622080679	,0.005102041]),
9:np.array([0.005460218,	0.00131406	,0.003663004,	0.014198005	,0.066176471,	0	,0.009586579,	0.006369427,0.224489796]),
}
glc_dict = {
1:np.array([0.810240964,	0.053763441,	0.083333333,	0.051973051,	0.022123894	,0	,0.020722635,	0.114973262,	0.375]),
2:np.array([0.054216867,	0.844470046,	0.42	,0.035129933,	0.004424779,	0,	0,	0.00802139,	0.020833333]),
3:np.array([0.034471218,	0.050691244	,0.23,	0.06400385,	0,	0.002906977,	0.023379384,	0.016042781,	0]),
4:np.array([0.032797858	,0.032642089,	0.06,	0.664581328	,0,	0.005813953,	0.089266738	,0.002673797	,0.166666667]),
5:np.array([0.014390897	,0.005376344,	0	,0.007218479,	0.889380531,	0	,0.003188098,	0.010695187	,0.104166667]),
6:np.array([0	,0.005376344,	0.003333333,	0.045717036,	0.030973451,	0.927325581,	0.021785335,	0,	0]),
7:np.array([0.004016064,	0.001152074,	0.203333333,	0.104908566,	0.004424779,	0.058139535,0.829968119,	0.002673797,	0.041666667]),
8:np.array([0.036144578	,0.004608295,	0,	0.005774783,	0.004424779,	0	,0.002656748,	0.831550802,	0]),
9:np.array([0.013721553,	0.001920123,	0	,0.020692974,	0.044247788,0.005813953,	0.009032944,	0.013368984	,0.291666667])}
csv_file = "unique_values_output_2020.csv"
chunk_size = 1000000  # 每个块的大小
result_file = "2020_csj.csv"  # 存储结果的文件
for chunk in pd.read_csv(csv_file, chunksize=chunk_size):
    data1 = chunk[["FID", "CLCD", "LUCC", "GLC"]].values
    result_list = []  # 用于存储分类结果
    for i in range(len(data1)):
        oid = data1[i, 0]
        clcdvalue = data1[i, 1]
        luccvalue = data1[i, 2]
        glcvalue = data1[i, 3]

        clcdarr = clcd_dict.get(clcdvalue, np.zeros(9))
        luccarr = lucc_dict.get(luccvalue, np.zeros(9))
        glcarr = glc_dict.get(glcvalue, np.zeros(9))

        result = fusion(clcdarr, luccarr, glcarr, oid)
        if result is not None:
            result_list.append(result)
    with tqdm(total=len(result_list), desc="Processing Results") as pbar:
        for result in result_list:
            # Your result processing code here

            # Update the progress bar
            pbar.update(1)
    # 写入结果到文件
    with open(result_file, "a") as csvfile:
        writer = csv.writer(csvfile)
        writer.writerows(result_list)